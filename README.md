# tutoria-mlops-challenge

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o completa do desafio final da Tutoria MLOps, com o objetivo de construir um **pipeline de Machine Learning reprodutÃ­vel, rastreÃ¡vel, versionado e pronto para produÃ§Ã£o**, seguindo boas prÃ¡ticas de MLOps NÃ­vel 0 â†’ NÃ­vel 1.

O projeto envolve:

- ingestÃ£o e preparaÃ§Ã£o de dados de sentimento da Amazon (Kaggle),
- versionamento e armazenamento em S3,
- treinamento e rastreamento de modelos com MLflow,
- deploy de API de inferÃªncia na AWS (Lambda ou ECS),
- simulaÃ§Ã£o de retraining em batch via Airflow,
- infraestrutura como cÃ³digo com Terraform,
- CI/CD com GitHub Actions e OIDC.

---

# ğŸ§© Premissas

- Linguagem principal: **Python 3.10+**
- Dataset: **Amazon Reviews Polarity** (supervisionado, binÃ¡rio)
- Armazenamento de dados: **S3**
- MLflow:
  - **Fase inicial:** execuÃ§Ã£o local (docker-compose)
  - **Fase avanÃ§ada:** servidor MLflow em ECS Fargate (tracking server)
  - Artifact store: **S3**
- Airflow:
  - Executado **localmente via Docker** (para evitar custo MWAA)
  - Orquestra pipelines remotos (ECS Tasks)
- API de inferÃªncia: **FastAPI** + Docker + AWS
- Infraestrutura via **Terraform** usando OIDC para GitHub Actions
- Dataset serÃ¡ dividido em **10 batches** para simular ingestÃ£o semanal
- Apenas **scripts de data engineering** rodam local;
  treinamento e serving rodam em **containers dedicados**

---

# ğŸ“… Planejamento do Projeto (Fases Evolutivas)

A execuÃ§Ã£o segue uma progressÃ£o clara:

---

## âœ” Fase 1 â€” EDA e Baselines (Notebook)

Objetivo: entender os dados e selecionar o modelo baseline.

### MLflow Setup
- Rodando via Docker local:
  - UI disponÃ­vel em `http://localhost:5000`
  - Backend local
  - Artifacts local

### `notebooks/eda_01.ipynb`
- Baixar amostra do dataset
- Explorar classes, tamanhos e exemplos
- Definir qual tipo(s) de modelo serÃ¡ utilizado
- Criar `full_text = title + text`
- Treinar 2 modelos baseline: (na etapa de definiÃ§Ã£o dos modelos optou-se por modelos lineares)
   - TF-IDF + LogisticRegression
   - TF-IDF + LinearSVC
- Avaliar mÃ©tricas:
   - Accuracy
   - Precision
   - Recall
   - F1-Macro
   - Confusion Matrix
- Selecionar modelo â€œv1â€
- Registrar runs no MLflow local

---

## âœ” Fase 2 â€” Data Pipeline (Scripts Modulares)

Transformar cÃ³digo do notebook em scripts reusÃ¡veis:

### `src/model/data/ingest.py`
- Baixa dataset (local)
- Salva raw em `data/raw/`

### `src/model/data/split_batches.py`
- Divide dataset em **10 batches** iguais
- Salva em `data/batches/batch_0..9.parquet`

### `src/model/data/preprocess_core.py`
- Limpeza e padronizaÃ§Ã£o
- ConcatenaÃ§Ã£o de texto
- Salva Parquet em `data/processed/`

### `src/model/data/preprocess_test.py`
- Aplica o `preprocess_core` no dado de teste
- Salva Parquet em `data/processed/`

---

## âœ” Fase 3 â€” Treinamento com MLflow (NÃ­vel 0 â†’ 1)

Implementar um pipeline reprodutÃ­vel:

### `src/model/data/preprocess_batch.py`
- Aplica o `preprocess_core` em um batch especÃ­fico
- Salva Parquet em `data/processed/`

### `src/model/pipeline/train.py`
- Recebe `--batches 0..k`
- Concatena batches
    > TF-IDF e modelos lineares nÃ£o suportam aprendizado incremental nativo; por isso, o retraining sempre usa batchâ‚€..batchâ‚–, garantindo vocabulÃ¡rio consistente.
- Split interno 80/20 (train/val)
- Treina modelo baseline
- Loga mÃ©tricas no MLflow
- Salva artefatos do modelo no MLflow â†’ S3

### `src/model/pipeline/evaluate.py`
- Avalia no test set global
- Loga mÃ©tricas no MLflow

### `src/model/pipeline/predict.py`
- Recebe `--title "title" --message "message"`
- Formata o input
- Faz prediÃ§Ã£o do valor

### Training Container
- Dockerfile para treinar em ECS Task

---

## âœ” Fase 4 â€” Serving (API de InferÃªncia)

Implementar API FastAPI que carrega modelo do MLflow/S3:

### `src/serving/app.py`
- API FastAPI com endpoints:
  - `POST /predict`
  - `GET /health`
- Carregamento do modelo latest do S3/MLflow, via MLflow Model Artifact

---

## âœ” Fase 5 â€” Monitoramento

Monitorar:

- DistribuiÃ§Ã£o de prediÃ§Ãµes (drift)

## âœ” Fase 6 â€” Deploy e IaC (Terraform + CI/CD)

Containers:
- MlFlow
- Model
- Training
- Monitoring

Infra via Terraform:

- S3 (datasets + artifacts)
- ECR (imagens de treino e serving)
- ECS Fargate para serving
- IAM Roles + GitHub OIDC
- MLflow Tracking Server em ECS Fargate

GitHub Actions:
- build & push de imagens
- terraform plan/apply
- deploy automatizado da API
- testes com 80% de cobertura
- lint com ruff

---

## âœ” Fase 7 â€” Airflow (OrquestraÃ§Ã£o do Pipeline)

Airflow rodarÃ¡ *local*, mas orquestrarÃ¡ tarefas na AWS:

- ingestÃ£o (manual)
- batch split
- preprocess
- treino inicial
- retraining semanal:
  `batch_0 â†’ batch_0..1 â†’ batch_0..2 â†’ â€¦`
- geraÃ§Ã£o de report de drift

Cada etapa de ML Ã© executada via **ECS Task**.
SerÃ£o 3 Dags

---

# ğŸ§­ Estrutura Final do Projeto (Tree â€œv1â€)

```text
tutoria-mlops-challenge/
â”œâ”€â”€ notebooks/          # EDA e experimentaÃ§Ã£o
â”œâ”€â”€ src/                # CÃ³digo de ingestÃ£o, preprocess, treino, serving
â”‚   â”œâ”€â”€ data/           # Scripts de pipeline de dados
â”‚   â”œâ”€â”€ models/         # Treinamento e avaliaÃ§Ã£o
â”‚   â””â”€â”€ serving/        # API FastAPI
â”œâ”€â”€ airflow/            # OrquestraÃ§Ã£o local via docker-compose
â”œâ”€â”€ mlflow/             # MLflow local via docker-compose
â”œâ”€â”€ infra/              # Terraform (AWS S3, ECR, ECS, IAM, OIDC)
â”œâ”€â”€ docker/             # Dockerfiles e configuraÃ§Ãµes auxiliares
â”œâ”€â”€ Makefile            # Comandos Ãºteis
â”œâ”€â”€ requirements.txt    # DependÃªncias
â””â”€â”€ README.md
```

# ğŸ™ Agradecimentos

AgradeÃ§o aos tutores pelo apoio, didÃ¡tica e incentivo:
- Manoel VerÃ­ssimo â€“ [verissimomanoel](https://github.com/verissimomanoel)
- Douglas Batista â€“ [dougbatista](https://github.com/dougbatista)
- Rafael Teru