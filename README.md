# tutoria-mlops-challenge

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o completa do desafio final da Tutoria MLOps, com o objetivo de construir um **pipeline de Machine Learning reprodutÃ­vel, rastreÃ¡vel, versionado e pronto para produÃ§Ã£o**, seguindo boas prÃ¡ticas de MLOps NÃ­vel 0 â†’ NÃ­vel 1.

O projeto envolve:

- ingestÃ£o e preparaÃ§Ã£o de dados de sentimento da Amazon (Kaggle),
- versionamento e armazenamento em S3,
- treinamento e rastreamento de modelos com MLflow,
- deploy de API de inferÃªncia na AWS (Lambda ou ECS),
- simulaÃ§Ã£o de retraining em batch via Airflow,
- infraestrutura como cÃ³digo com Terraform,
- CI/CD com GitHub Actions e OIDC.

---

# ğŸ§© Premissas

- Linguagem principal: **Python 3.10+**
- Dataset: **Amazon Reviews Polarity** (supervisionado, binÃ¡rio)
- Armazenamento de dados: **S3**
- MLflow:
  - **Fase inicial:** execuÃ§Ã£o local (docker-compose)
  - **Fase avanÃ§ada:** servidor MLflow em ECS Fargate (tracking server)
  - Artifact store: **S3**
- Airflow:
  - Executado **localmente via Docker** (para evitar custo MWAA)
  - Orquestra pipelines remotos (ECS Tasks)
- API de inferÃªncia: **FastAPI** + Docker + AWS
- Infraestrutura via **Terraform** usando OIDC para GitHub Actions
- Dataset serÃ¡ dividido em **10 batches** para simular ingestÃ£o semanal
- Apenas **scripts de data engineering** rodam local;
  treinamento e serving rodam em **containers dedicados**

---

# ğŸ“… Planejamento do Projeto (Fases Evolutivas)

A execuÃ§Ã£o segue uma progressÃ£o clara:

---

## âœ” Fase 1 â€” EDA e Baselines (Notebook)

Objetivo: entender os dados e selecionar o modelo baseline.

1. Criar `notebooks/eda_01.ipynb`
2. Baixar amostra do dataset
3. Explorar classes, tamanhos e exemplos
4. Criar `full_text = title + text`
5. Treinar 2 modelos baseline:
   - TF-IDF + LogisticRegression
   - TF-IDF + LinearSVC
6. Avaliar mÃ©tricas:
   - Accuracy
   - Precision
   - Recall
   - F1-Macro
   - Confusion Matrix
7. Selecionar modelo â€œv1â€
8. Registrar runs no MLflow local

---

## âœ” Fase 2 â€” Data Pipeline (Scripts Modulares)

Transformar cÃ³digo do notebook em scripts reusÃ¡veis:

### `src/data/ingest.py`
- Baixa dataset (local)
- Salva raw em `data/raw/`

### `src/data/preprocess.py`
- Limpeza e padronizaÃ§Ã£o
- ConcatenaÃ§Ã£o de texto
- Salva Parquet em `data/processed/`

### `src/data/split_batches.py`
- Divide dataset em **10 batches** iguais
- Salva em `data/batches/batch_0..9.parquet`

---

## âœ” Fase 3 â€” Treinamento com MLflow (NÃ­vel 0 â†’ 1)

Implementar um pipeline reprodutÃ­vel:

### `src/models/train.py`
- Recebe `--batches 0..k`
- Concatena batches
    > TF-IDF e modelos lineares nÃ£o suportam aprendizado incremental nativo; por isso, o retraining sempre usa batchâ‚€..batchâ‚–, garantindo vocabulÃ¡rio consistente.
- Split interno 80/20 (train/val)
- Treina modelo baseline
- Loga mÃ©tricas no MLflow
- Salva artefatos do modelo no MLflow â†’ S3

### `src/models/evaluate.py`
- Avalia no test set global
- Loga mÃ©tricas no MLflow

### MLflow Setup
- Rodando via Docker local:
  - UI disponÃ­vel em `http://localhost:5000`
  - Backend local
  - Artifacts no S3 (ou local no inÃ­cio)

### Training Container
- Dockerfile para treinar em ECS Task

---

## âœ” Fase 4 â€” Serving (API de InferÃªncia)

Implementar API FastAPI que carrega modelo do MLflow/S3:

### `src/serving/app.py`
- API FastAPI com endpoints:
  - `POST /predict`
  - `GET /health`
- Carregamento do modelo versÃ£o XX do S3/MLflow, via MLflow Model Artifact

### API Container
- Dockerfile da API

---

## âœ” Fase 5 â€” Airflow (OrquestraÃ§Ã£o do Pipeline)

Airflow rodarÃ¡ *local*, mas orquestrarÃ¡ tarefas na AWS:

- ingestÃ£o (manual)
- preprocess
- batch split
- treino inicial
- retraining semanal:
  `batch_0 â†’ batch_0..1 â†’ batch_0..2 â†’ â€¦`

Cada etapa de ML Ã© executada via **ECS Task**.

> A DAG serÃ¡ Ãºnica, contendo seÃ§Ãµes claras para:
>
> Data Engineering â†’ Training â†’ Retraining.
>
> Uma Ãºnica DAG facilita rastreabilidade, versionamento e depuraÃ§Ã£o do pipeline inteiro.

---

## âœ” Fase 6 â€” Deploy e IaC (Terraform + CI/CD)

Infra via Terraform:

- S3 (datasets + artifacts)
- ECR (imagens de treino e serving)
- Lambda ou ECS Fargate para serving
- IAM Roles + GitHub OIDC
- EventBridge (opcional para retraining futuro)
- MLflow Tracking Server em ECS Fargate (fase avanÃ§ada)

GitHub Actions:
- build & push de imagens
- terraform plan/apply
- deploy automatizado da API

---

## âœ” Fase 7 â€” Monitoramento

Monitorar:

- LatÃªncia e erros da API
- DistribuiÃ§Ã£o de prediÃ§Ãµes (drift)
- MÃ©tricas de cada retraining (MLflow)
- Logs do ECS/Lambda

---

# ğŸ§­ Estrutura Final do Projeto (Tree â€œv1â€)

```text
tutoria-mlops-challenge/
â”œâ”€â”€ notebooks/          # EDA e experimentaÃ§Ã£o
â”œâ”€â”€ src/                # CÃ³digo de ingestÃ£o, preprocess, treino, serving
â”‚   â”œâ”€â”€ data/           # Scripts de pipeline de dados
â”‚   â”œâ”€â”€ models/         # Treinamento e avaliaÃ§Ã£o
â”‚   â””â”€â”€ serving/        # API FastAPI
â”œâ”€â”€ airflow/            # OrquestraÃ§Ã£o local via docker-compose
â”œâ”€â”€ mlflow/             # MLflow local via docker-compose
â”œâ”€â”€ infra/              # Terraform (AWS S3, ECR, ECS, IAM, OIDC)
â”œâ”€â”€ docker/             # Dockerfiles e configuraÃ§Ãµes auxiliares
â”œâ”€â”€ docs/               # DocumentaÃ§Ã£o para o GitHub Pages
â”œâ”€â”€ Makefile            # Comandos Ãºteis
â”œâ”€â”€ requirements.txt    # DependÃªncias
â””â”€â”€ README.md
```

# ğŸ™ Agradecimentos

AgradeÃ§o aos tutores pelo apoio, didÃ¡tica e incentivo:
- Manoel VerÃ­ssimo â€“ [verissimomanoel](https://github.com/verissimomanoel)
- Douglas Batista â€“ [dougbatista](https://github.com/dougbatista)